{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8b7kTQL_H902"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### building a model data\n",
        "\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "hello = torch.arange(start=0, end = 1 , step = 0.002).unsqueeze(dim=1)\n",
        "bro = weight*hello+ bias\n",
        "\n",
        "hello[:10],bro[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toEw22Q2IH4p",
        "outputId": "b0c50a75-598c-4d7c-9b5f-2ea15a212cbd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0020],\n",
              "         [0.0040],\n",
              "         [0.0060],\n",
              "         [0.0080],\n",
              "         [0.0100],\n",
              "         [0.0120],\n",
              "         [0.0140],\n",
              "         [0.0160],\n",
              "         [0.0180]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3014],\n",
              "         [0.3028],\n",
              "         [0.3042],\n",
              "         [0.3056],\n",
              "         [0.3070],\n",
              "         [0.3084],\n",
              "         [0.3098],\n",
              "         [0.3112],\n",
              "         [0.3126]]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len (hello), len (bro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAuWp0UjJmC3",
        "outputId": "3a78dfb3-bfd2-46ae-e4b4-f4963e3ab718"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### here i would be focusing on splitting the data into train and test sets mate"
      ],
      "metadata": {
        "id": "DcoxqiWCK-Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ## there are three types of sets\n",
        " ## 1. training set - 60 - 80%\n",
        " ## 2. validation set - not all models have it but mostly 10 %\n",
        " ## 3. test set - 10 - 30%"
      ],
      "metadata": {
        "id": "Vr-tA6hEKVpL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8*len(hello))\n",
        "hello_train, bro_train = hello[:train_split],bro[:train_split]\n",
        "hello_test, bro_test = hello[train_split:],bro[train_split:]\n",
        "\n",
        "len(hello_test),len(hello_train),len(bro_test),len(bro_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mFZNN1uLUzi",
        "outputId": "756e83bc-9a89-4f00-aeea-9576919d98b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 400, 100, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "alright lets use matplotlib to make it more amusing as a firework less goo"
      ],
      "metadata": {
        "id": "X8NAgjO-N5Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graphy(train_data = hello_train,\n",
        "           train_label= bro_train,\n",
        "           test_data = hello_test,\n",
        "           test_label= bro_test,\n",
        "           predictions = None):\n",
        "\n",
        "    plt.figure(figsize=(6,9))\n",
        "\n",
        "    plt.scatter(train_data,train_label,c=\"r\",s=5,label = \"training data\")\n",
        "    plt.scatter(test_data,test_label,c=\"g\",s=5,label=\"testing data\")\n",
        "\n",
        "    if predictions is not None:\n",
        "      plt.scatter(test_data,predictions,c=\"b\",s=10,label=\"predictions\")\n",
        "\n",
        "\n",
        "    plt.legend(prop={\"size\":14})\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dQ2qJXJSM-0N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "xJfV-LohQmRc",
        "outputId": "84c33110-665b-442b-990a-becb03e7be40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building model to fit data in the red line"
      ],
      "metadata": {
        "id": "hMFewdBxUNvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class linearregression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight=nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad=True,\n",
        "                                         dtype=torch.float))\n",
        "    self.bias=nn.Parameter(torch.randn(1,\n",
        "                                       requires_grad=True,\n",
        "                                       dtype=torch.float))\n",
        "\n",
        "  def forward(self,x:torch.Tensor) -> torch.tensor:\n",
        "    return self.weight * hello + self.bias"
      ],
      "metadata": {
        "id": "9B3u4fbEQtrx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "so we have few building blocks of pytorch that u have to understand\n",
        "\n",
        "1. torch.nn(neural network)\n",
        "2. torch.parameter\n",
        "3. torch.Module\n",
        "4. torch.optim = optimiser\n",
        "5. def forward() - > this means what is gonna happen to stuff in computation"
      ],
      "metadata": {
        "id": "ZkcfhX2gpKBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(69)\n",
        "\n",
        "model_bro = linearregression()\n",
        "\n",
        "list(model_bro.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Wg0DEIo-Fz",
        "outputId": "7ac0e331-fbc4-45e9-f67e-2b405d1c220b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([-0.5259], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-2.6043], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_bro.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3XJLPSrr763",
        "outputId": "003dd35f-e2e0-4a8d-eb9b-2d71548d2f22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([-0.5259])), ('bias', tensor([-2.6043]))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### alright so untill here we made some checking as to how the data models is being done\n"
      ],
      "metadata": {
        "id": "P-R0d7hDtFOQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets do predictions"
      ],
      "metadata": {
        "id": "38ZC58wUtdP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model_bro(hello_test)\n",
        "\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxbdWsqPtcU_",
        "outputId": "955e9b4c-63cb-41b6-b76e-b5500bc50529"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6043],\n",
              "        [-2.6053],\n",
              "        [-2.6064],\n",
              "        [-2.6074],\n",
              "        [-2.6085],\n",
              "        [-2.6095],\n",
              "        [-2.6106],\n",
              "        [-2.6116],\n",
              "        [-2.6127],\n",
              "        [-2.6137],\n",
              "        [-2.6148],\n",
              "        [-2.6158],\n",
              "        [-2.6169],\n",
              "        [-2.6179],\n",
              "        [-2.6190],\n",
              "        [-2.6200],\n",
              "        [-2.6211],\n",
              "        [-2.6221],\n",
              "        [-2.6232],\n",
              "        [-2.6243],\n",
              "        [-2.6253],\n",
              "        [-2.6264],\n",
              "        [-2.6274],\n",
              "        [-2.6285],\n",
              "        [-2.6295],\n",
              "        [-2.6306],\n",
              "        [-2.6316],\n",
              "        [-2.6327],\n",
              "        [-2.6337],\n",
              "        [-2.6348],\n",
              "        [-2.6358],\n",
              "        [-2.6369],\n",
              "        [-2.6379],\n",
              "        [-2.6390],\n",
              "        [-2.6400],\n",
              "        [-2.6411],\n",
              "        [-2.6421],\n",
              "        [-2.6432],\n",
              "        [-2.6442],\n",
              "        [-2.6453],\n",
              "        [-2.6463],\n",
              "        [-2.6474],\n",
              "        [-2.6484],\n",
              "        [-2.6495],\n",
              "        [-2.6505],\n",
              "        [-2.6516],\n",
              "        [-2.6527],\n",
              "        [-2.6537],\n",
              "        [-2.6548],\n",
              "        [-2.6558],\n",
              "        [-2.6569],\n",
              "        [-2.6579],\n",
              "        [-2.6590],\n",
              "        [-2.6600],\n",
              "        [-2.6611],\n",
              "        [-2.6621],\n",
              "        [-2.6632],\n",
              "        [-2.6642],\n",
              "        [-2.6653],\n",
              "        [-2.6663],\n",
              "        [-2.6674],\n",
              "        [-2.6684],\n",
              "        [-2.6695],\n",
              "        [-2.6705],\n",
              "        [-2.6716],\n",
              "        [-2.6726],\n",
              "        [-2.6737],\n",
              "        [-2.6747],\n",
              "        [-2.6758],\n",
              "        [-2.6768],\n",
              "        [-2.6779],\n",
              "        [-2.6789],\n",
              "        [-2.6800],\n",
              "        [-2.6810],\n",
              "        [-2.6821],\n",
              "        [-2.6832],\n",
              "        [-2.6842],\n",
              "        [-2.6853],\n",
              "        [-2.6863],\n",
              "        [-2.6874],\n",
              "        [-2.6884],\n",
              "        [-2.6895],\n",
              "        [-2.6905],\n",
              "        [-2.6916],\n",
              "        [-2.6926],\n",
              "        [-2.6937],\n",
              "        [-2.6947],\n",
              "        [-2.6958],\n",
              "        [-2.6968],\n",
              "        [-2.6979],\n",
              "        [-2.6989],\n",
              "        [-2.7000],\n",
              "        [-2.7010],\n",
              "        [-2.7021],\n",
              "        [-2.7031],\n",
              "        [-2.7042],\n",
              "        [-2.7052],\n",
              "        [-2.7063],\n",
              "        [-2.7073],\n",
              "        [-2.7084],\n",
              "        [-2.7094],\n",
              "        [-2.7105],\n",
              "        [-2.7116],\n",
              "        [-2.7126],\n",
              "        [-2.7137],\n",
              "        [-2.7147],\n",
              "        [-2.7158],\n",
              "        [-2.7168],\n",
              "        [-2.7179],\n",
              "        [-2.7189],\n",
              "        [-2.7200],\n",
              "        [-2.7210],\n",
              "        [-2.7221],\n",
              "        [-2.7231],\n",
              "        [-2.7242],\n",
              "        [-2.7252],\n",
              "        [-2.7263],\n",
              "        [-2.7273],\n",
              "        [-2.7284],\n",
              "        [-2.7294],\n",
              "        [-2.7305],\n",
              "        [-2.7315],\n",
              "        [-2.7326],\n",
              "        [-2.7336],\n",
              "        [-2.7347],\n",
              "        [-2.7357],\n",
              "        [-2.7368],\n",
              "        [-2.7378],\n",
              "        [-2.7389],\n",
              "        [-2.7399],\n",
              "        [-2.7410],\n",
              "        [-2.7421],\n",
              "        [-2.7431],\n",
              "        [-2.7442],\n",
              "        [-2.7452],\n",
              "        [-2.7463],\n",
              "        [-2.7473],\n",
              "        [-2.7484],\n",
              "        [-2.7494],\n",
              "        [-2.7505],\n",
              "        [-2.7515],\n",
              "        [-2.7526],\n",
              "        [-2.7536],\n",
              "        [-2.7547],\n",
              "        [-2.7557],\n",
              "        [-2.7568],\n",
              "        [-2.7578],\n",
              "        [-2.7589],\n",
              "        [-2.7599],\n",
              "        [-2.7610],\n",
              "        [-2.7620],\n",
              "        [-2.7631],\n",
              "        [-2.7641],\n",
              "        [-2.7652],\n",
              "        [-2.7662],\n",
              "        [-2.7673],\n",
              "        [-2.7683],\n",
              "        [-2.7694],\n",
              "        [-2.7705],\n",
              "        [-2.7715],\n",
              "        [-2.7726],\n",
              "        [-2.7736],\n",
              "        [-2.7747],\n",
              "        [-2.7757],\n",
              "        [-2.7768],\n",
              "        [-2.7778],\n",
              "        [-2.7789],\n",
              "        [-2.7799],\n",
              "        [-2.7810],\n",
              "        [-2.7820],\n",
              "        [-2.7831],\n",
              "        [-2.7841],\n",
              "        [-2.7852],\n",
              "        [-2.7862],\n",
              "        [-2.7873],\n",
              "        [-2.7883],\n",
              "        [-2.7894],\n",
              "        [-2.7904],\n",
              "        [-2.7915],\n",
              "        [-2.7925],\n",
              "        [-2.7936],\n",
              "        [-2.7946],\n",
              "        [-2.7957],\n",
              "        [-2.7967],\n",
              "        [-2.7978],\n",
              "        [-2.7988],\n",
              "        [-2.7999],\n",
              "        [-2.8010],\n",
              "        [-2.8020],\n",
              "        [-2.8031],\n",
              "        [-2.8041],\n",
              "        [-2.8052],\n",
              "        [-2.8062],\n",
              "        [-2.8073],\n",
              "        [-2.8083],\n",
              "        [-2.8094],\n",
              "        [-2.8104],\n",
              "        [-2.8115],\n",
              "        [-2.8125],\n",
              "        [-2.8136],\n",
              "        [-2.8146],\n",
              "        [-2.8157],\n",
              "        [-2.8167],\n",
              "        [-2.8178],\n",
              "        [-2.8188],\n",
              "        [-2.8199],\n",
              "        [-2.8209],\n",
              "        [-2.8220],\n",
              "        [-2.8230],\n",
              "        [-2.8241],\n",
              "        [-2.8251],\n",
              "        [-2.8262],\n",
              "        [-2.8272],\n",
              "        [-2.8283],\n",
              "        [-2.8294],\n",
              "        [-2.8304],\n",
              "        [-2.8315],\n",
              "        [-2.8325],\n",
              "        [-2.8336],\n",
              "        [-2.8346],\n",
              "        [-2.8357],\n",
              "        [-2.8367],\n",
              "        [-2.8378],\n",
              "        [-2.8388],\n",
              "        [-2.8399],\n",
              "        [-2.8409],\n",
              "        [-2.8420],\n",
              "        [-2.8430],\n",
              "        [-2.8441],\n",
              "        [-2.8451],\n",
              "        [-2.8462],\n",
              "        [-2.8472],\n",
              "        [-2.8483],\n",
              "        [-2.8493],\n",
              "        [-2.8504],\n",
              "        [-2.8514],\n",
              "        [-2.8525],\n",
              "        [-2.8535],\n",
              "        [-2.8546],\n",
              "        [-2.8556],\n",
              "        [-2.8567],\n",
              "        [-2.8577],\n",
              "        [-2.8588],\n",
              "        [-2.8599],\n",
              "        [-2.8609],\n",
              "        [-2.8620],\n",
              "        [-2.8630],\n",
              "        [-2.8641],\n",
              "        [-2.8651],\n",
              "        [-2.8662],\n",
              "        [-2.8672],\n",
              "        [-2.8683],\n",
              "        [-2.8693],\n",
              "        [-2.8704],\n",
              "        [-2.8714],\n",
              "        [-2.8725],\n",
              "        [-2.8735],\n",
              "        [-2.8746],\n",
              "        [-2.8756],\n",
              "        [-2.8767],\n",
              "        [-2.8777],\n",
              "        [-2.8788],\n",
              "        [-2.8798],\n",
              "        [-2.8809],\n",
              "        [-2.8819],\n",
              "        [-2.8830],\n",
              "        [-2.8840],\n",
              "        [-2.8851],\n",
              "        [-2.8861],\n",
              "        [-2.8872],\n",
              "        [-2.8882],\n",
              "        [-2.8893],\n",
              "        [-2.8904],\n",
              "        [-2.8914],\n",
              "        [-2.8925],\n",
              "        [-2.8935],\n",
              "        [-2.8946],\n",
              "        [-2.8956],\n",
              "        [-2.8967],\n",
              "        [-2.8977],\n",
              "        [-2.8988],\n",
              "        [-2.8998],\n",
              "        [-2.9009],\n",
              "        [-2.9019],\n",
              "        [-2.9030],\n",
              "        [-2.9040],\n",
              "        [-2.9051],\n",
              "        [-2.9061],\n",
              "        [-2.9072],\n",
              "        [-2.9082],\n",
              "        [-2.9093],\n",
              "        [-2.9103],\n",
              "        [-2.9114],\n",
              "        [-2.9124],\n",
              "        [-2.9135],\n",
              "        [-2.9145],\n",
              "        [-2.9156],\n",
              "        [-2.9166],\n",
              "        [-2.9177],\n",
              "        [-2.9188],\n",
              "        [-2.9198],\n",
              "        [-2.9209],\n",
              "        [-2.9219],\n",
              "        [-2.9230],\n",
              "        [-2.9240],\n",
              "        [-2.9251],\n",
              "        [-2.9261],\n",
              "        [-2.9272],\n",
              "        [-2.9282],\n",
              "        [-2.9293],\n",
              "        [-2.9303],\n",
              "        [-2.9314],\n",
              "        [-2.9324],\n",
              "        [-2.9335],\n",
              "        [-2.9345],\n",
              "        [-2.9356],\n",
              "        [-2.9366],\n",
              "        [-2.9377],\n",
              "        [-2.9387],\n",
              "        [-2.9398],\n",
              "        [-2.9408],\n",
              "        [-2.9419],\n",
              "        [-2.9429],\n",
              "        [-2.9440],\n",
              "        [-2.9450],\n",
              "        [-2.9461],\n",
              "        [-2.9471],\n",
              "        [-2.9482],\n",
              "        [-2.9493],\n",
              "        [-2.9503],\n",
              "        [-2.9514],\n",
              "        [-2.9524],\n",
              "        [-2.9535],\n",
              "        [-2.9545],\n",
              "        [-2.9556],\n",
              "        [-2.9566],\n",
              "        [-2.9577],\n",
              "        [-2.9587],\n",
              "        [-2.9598],\n",
              "        [-2.9608],\n",
              "        [-2.9619],\n",
              "        [-2.9629],\n",
              "        [-2.9640],\n",
              "        [-2.9650],\n",
              "        [-2.9661],\n",
              "        [-2.9671],\n",
              "        [-2.9682],\n",
              "        [-2.9692],\n",
              "        [-2.9703],\n",
              "        [-2.9713],\n",
              "        [-2.9724],\n",
              "        [-2.9734],\n",
              "        [-2.9745],\n",
              "        [-2.9755],\n",
              "        [-2.9766],\n",
              "        [-2.9777],\n",
              "        [-2.9787],\n",
              "        [-2.9798],\n",
              "        [-2.9808],\n",
              "        [-2.9819],\n",
              "        [-2.9829],\n",
              "        [-2.9840],\n",
              "        [-2.9850],\n",
              "        [-2.9861],\n",
              "        [-2.9871],\n",
              "        [-2.9882],\n",
              "        [-2.9892],\n",
              "        [-2.9903],\n",
              "        [-2.9913],\n",
              "        [-2.9924],\n",
              "        [-2.9934],\n",
              "        [-2.9945],\n",
              "        [-2.9955],\n",
              "        [-2.9966],\n",
              "        [-2.9976],\n",
              "        [-2.9987],\n",
              "        [-2.9997],\n",
              "        [-3.0008],\n",
              "        [-3.0018],\n",
              "        [-3.0029],\n",
              "        [-3.0039],\n",
              "        [-3.0050],\n",
              "        [-3.0060],\n",
              "        [-3.0071],\n",
              "        [-3.0082],\n",
              "        [-3.0092],\n",
              "        [-3.0103],\n",
              "        [-3.0113],\n",
              "        [-3.0124],\n",
              "        [-3.0134],\n",
              "        [-3.0145],\n",
              "        [-3.0155],\n",
              "        [-3.0166],\n",
              "        [-3.0176],\n",
              "        [-3.0187],\n",
              "        [-3.0197],\n",
              "        [-3.0208],\n",
              "        [-3.0218],\n",
              "        [-3.0229],\n",
              "        [-3.0239],\n",
              "        [-3.0250],\n",
              "        [-3.0260],\n",
              "        [-3.0271],\n",
              "        [-3.0281],\n",
              "        [-3.0292],\n",
              "        [-3.0302],\n",
              "        [-3.0313],\n",
              "        [-3.0323],\n",
              "        [-3.0334],\n",
              "        [-3.0344],\n",
              "        [-3.0355],\n",
              "        [-3.0366],\n",
              "        [-3.0376],\n",
              "        [-3.0387],\n",
              "        [-3.0397],\n",
              "        [-3.0408],\n",
              "        [-3.0418],\n",
              "        [-3.0429],\n",
              "        [-3.0439],\n",
              "        [-3.0450],\n",
              "        [-3.0460],\n",
              "        [-3.0471],\n",
              "        [-3.0481],\n",
              "        [-3.0492],\n",
              "        [-3.0502],\n",
              "        [-3.0513],\n",
              "        [-3.0523],\n",
              "        [-3.0534],\n",
              "        [-3.0544],\n",
              "        [-3.0555],\n",
              "        [-3.0565],\n",
              "        [-3.0576],\n",
              "        [-3.0586],\n",
              "        [-3.0597],\n",
              "        [-3.0607],\n",
              "        [-3.0618],\n",
              "        [-3.0628],\n",
              "        [-3.0639],\n",
              "        [-3.0649],\n",
              "        [-3.0660],\n",
              "        [-3.0671],\n",
              "        [-3.0681],\n",
              "        [-3.0692],\n",
              "        [-3.0702],\n",
              "        [-3.0713],\n",
              "        [-3.0723],\n",
              "        [-3.0734],\n",
              "        [-3.0744],\n",
              "        [-3.0755],\n",
              "        [-3.0765],\n",
              "        [-3.0776],\n",
              "        [-3.0786],\n",
              "        [-3.0797],\n",
              "        [-3.0807],\n",
              "        [-3.0818],\n",
              "        [-3.0828],\n",
              "        [-3.0839],\n",
              "        [-3.0849],\n",
              "        [-3.0860],\n",
              "        [-3.0870],\n",
              "        [-3.0881],\n",
              "        [-3.0891],\n",
              "        [-3.0902],\n",
              "        [-3.0912],\n",
              "        [-3.0923],\n",
              "        [-3.0933],\n",
              "        [-3.0944],\n",
              "        [-3.0955],\n",
              "        [-3.0965],\n",
              "        [-3.0976],\n",
              "        [-3.0986],\n",
              "        [-3.0997],\n",
              "        [-3.1007],\n",
              "        [-3.1018],\n",
              "        [-3.1028],\n",
              "        [-3.1039],\n",
              "        [-3.1049],\n",
              "        [-3.1060],\n",
              "        [-3.1070],\n",
              "        [-3.1081],\n",
              "        [-3.1091],\n",
              "        [-3.1102],\n",
              "        [-3.1112],\n",
              "        [-3.1123],\n",
              "        [-3.1133],\n",
              "        [-3.1144],\n",
              "        [-3.1154],\n",
              "        [-3.1165],\n",
              "        [-3.1175],\n",
              "        [-3.1186],\n",
              "        [-3.1196],\n",
              "        [-3.1207],\n",
              "        [-3.1217],\n",
              "        [-3.1228],\n",
              "        [-3.1238],\n",
              "        [-3.1249],\n",
              "        [-3.1260],\n",
              "        [-3.1270],\n",
              "        [-3.1281],\n",
              "        [-3.1291]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the ml model apparently sizes are same but not same"
      ],
      "metadata": {
        "id": "VpnkQ4gX57ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list (model_bro.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUU4JxFjwTO0",
        "outputId": "9e65a4fe-5a08-4fdb-8ff4-37bb4605a2a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([-0.5259], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-2.6043], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######loss function and optimiser being set up less go"
      ],
      "metadata": {
        "id": "S_RWakY967RS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function and optimiser come in both pair in pytorch"
      ],
      "metadata": {
        "id": "rvmWJrS18P0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossy =nn.L1Loss()\n",
        "\n",
        "optimo = torch.optim.SGD(params=model_bro.parameters(),\n",
        "                         lr=0.0)# lr  is learning rate"
      ],
      "metadata": {
        "id": "_E6l8rQL8BHZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ### building a loop in pytorch"
      ],
      "metadata": {
        "id": "GRBZeXHF9YPy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(69)\n",
        "\n",
        "epochs =1\n",
        "\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count=[]\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_bro.train()\n",
        "\n",
        "  ## forward pass\n",
        "\n",
        "  y_pred = model_bro(hello_train)\n",
        "\n",
        "  ## we be calculating the loss\n",
        "  losst = lossy(y_pred,bro_train)\n",
        "\n",
        "  optimo.zero_grad()\n",
        "\n",
        "  losst.backward()\n",
        "\n",
        "  optimo.step()\n",
        "\n",
        "\n",
        " ### testing\n",
        "  model_bro.eval()\n",
        " ## forward pass\n",
        "  # with torch.inference_mode():\n",
        "  #   test_pred = model_bro(hello_test)\n",
        "\n",
        "  #   test_loss = lossy(test_pred,bro_test)\n",
        "\n",
        "  #   if epoch % 10 == 0:\n",
        "  #     epoch_count.append(epoch)\n",
        "  #     train_loss_values.append(lossy.detach().numpy())\n",
        "  #     test_loss_values.append(test_loss.detach().numpy())\n",
        "  #     print(f\"epoch : {epoch}| Mean absolute loss : {loss}|mae test loss : {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "yPYmEwSo-kNX",
        "outputId": "b2d73ece-4abc-419e-e841-3ee2d1d14969"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([400, 1])) that is different to the input size (torch.Size([500, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.l1_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (500) must match the size of tensor b (400) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-35179b9fa036>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m## we be calculating the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mlosst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbro_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0moptimo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3295\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3297\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3298\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (500) must match the size of tensor b (400) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90OAaLTgqS81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}